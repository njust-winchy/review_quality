{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c1f283-dccf-4535-b2e6-0e7bf3e2e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "contractions = pd.read_csv('./contractions.csv', index_col='Contraction')\n",
    "contractions.index = contractions.index.str.lower()\n",
    "contractions.Meaning = contractions.Meaning.str.lower()\n",
    "contractions_dict = contractions.to_dict()['Meaning']\n",
    "\n",
    "# Defining regex patterns.\n",
    "urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\n",
    "userPattern       = '@[^\\s]+'\n",
    "hashtagPattern    = '#[^\\s]+'\n",
    "alphaPattern      = \"[^a-z0-9<>]\"\n",
    "sequencePattern   = r\"(.)\\1\\1+\"\n",
    "seqReplacePattern = r\"\\1\\1\"\n",
    "\n",
    "\n",
    "def preprocess_apply(tweet):\n",
    "\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # Replace all URls with '<url>'\n",
    "    tweet = re.sub(urlPattern,'<url>',tweet)\n",
    "    # Replace @USERNAME to '<user>'.\n",
    "    tweet = re.sub(userPattern,'<user>', tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "    tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "    for contraction, replacement in contractions_dict.items():\n",
    "        tweet = tweet.replace(contraction, replacement)\n",
    "\n",
    "    # Remove non-alphanumeric and symbols\n",
    "    tweet = re.sub(alphaPattern, ' ', tweet)\n",
    "\n",
    "    # Adding space on either side of '/' to seperate words (After replacing URLS).\n",
    "    tweet = re.sub(r'/', ' / ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1035a01-55de-4042-a6c0-14836c53647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20193</td>\n",
       "      <td>This paper presents a new approach to learning...</td>\n",
       "      <td>this paper presents a new approach to learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20193</td>\n",
       "      <td>The model, FAVAE, is based on the information ...</td>\n",
       "      <td>the model  favae  is based on the information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20193</td>\n",
       "      <td>The authors demonstrate that their approach is...</td>\n",
       "      <td>the authors demonstrate that their approach is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20193</td>\n",
       "      <td>I also like the approach that the authors are ...</td>\n",
       "      <td>i also like the approach that the authors are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20193</td>\n",
       "      <td>However, the paper could be improved by clarif...</td>\n",
       "      <td>however  the paper could be improved by clarif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35451</th>\n",
       "      <td>20194748</td>\n",
       "      <td>2: Change \"Linear Discriminant\" to \"linear dis...</td>\n",
       "      <td>2  change  linear discriminant  to  linear dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35452</th>\n",
       "      <td>20194748</td>\n",
       "      <td>Also, remove--------the abbreviations (SVM and...</td>\n",
       "      <td>also  remove  the abbreviations  svm and lda  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35453</th>\n",
       "      <td>20194748</td>\n",
       "      <td>5: Delete comma in \"assumption, that.\"--------...</td>\n",
       "      <td>5  delete comma in  assumption  that    p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35454</th>\n",
       "      <td>20194748</td>\n",
       "      <td>8: \"nearly perfect\" -&gt; \"nearly perfectly\"-----...</td>\n",
       "      <td>8   nearly perfect   &gt;  nearly perfectly   the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35455</th>\n",
       "      <td>20194748</td>\n",
       "      <td>Also, it would be better to order the classes-...</td>\n",
       "      <td>also  it would be better to order the classes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35456 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id                                             review  \\\n",
       "0          20193  This paper presents a new approach to learning...   \n",
       "1          20193  The model, FAVAE, is based on the information ...   \n",
       "2          20193  The authors demonstrate that their approach is...   \n",
       "3          20193  I also like the approach that the authors are ...   \n",
       "4          20193  However, the paper could be improved by clarif...   \n",
       "...          ...                                                ...   \n",
       "35451   20194748  2: Change \"Linear Discriminant\" to \"linear dis...   \n",
       "35452   20194748  Also, remove--------the abbreviations (SVM and...   \n",
       "35453   20194748  5: Delete comma in \"assumption, that.\"--------...   \n",
       "35454   20194748  8: \"nearly perfect\" -> \"nearly perfectly\"-----...   \n",
       "35455   20194748  Also, it would be better to order the classes-...   \n",
       "\n",
       "                                          processed_text  \n",
       "0      this paper presents a new approach to learning...  \n",
       "1      the model  favae  is based on the information ...  \n",
       "2      the authors demonstrate that their approach is...  \n",
       "3      i also like the approach that the authors are ...  \n",
       "4      however  the paper could be improved by clarif...  \n",
       "...                                                  ...  \n",
       "35451  2  change  linear discriminant  to  linear dis...  \n",
       "35452  also  remove  the abbreviations  svm and lda  ...  \n",
       "35453         5  delete comma in  assumption  that    p   \n",
       "35454  8   nearly perfect   >  nearly perfectly   the...  \n",
       "35455  also  it would be better to order the classes ...  \n",
       "\n",
       "[35456 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iclr_2019_sentence.csv')\n",
    "df['processed_text'] = df.review.apply(preprocess_apply)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adde2339-ae9f-4c7d-a86e-87a010f89cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Length: 6712\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "Word2vec_data = list(map(lambda x: x.split(), df['processed_text'].values))\n",
    "\n",
    "# Defining the model and training it.\n",
    "word2vec_model = Word2Vec(Word2vec_data,\n",
    "                 vector_size = 300,\n",
    "                 workers = 8\n",
    "#                  min_count=5\n",
    "                )\n",
    "\n",
    "print(\"Vocabulary Length:\", len(word2vec_model.wv.key_to_index))\n",
    "final_data = pd.read_csv('iclr_2019_sentence.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f9c8dd-dcd2-4371-a40b-f9d22873d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 15:26:22.017965: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab length: 7212\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#%%\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(df['processed_text'].values)\n",
    "VOCAB_LEN = len(word2vec_model.wv.key_to_index) + 500\n",
    "tokenizer.num_words = VOCAB_LEN\n",
    "print(\"Tokenizer vocab length:\", tokenizer.num_words)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(final_data.review.values), maxlen=768)\n",
    "pd.DataFrame(X_train).to_csv('Tokennized_Processed-BiLSTM-2019.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1c20bd-0ee0-4281-ab08-1e078cfd745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = './Tokennized_Processed-BiLSTM-2019.csv'\n",
    "custom_val_embeds = pd.read_csv(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805336e6-af3b-4e5c-bd33-458448c69d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Bidirectional, Input, Dense, Layer, Dropout, LSTM, Embedding, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833ae38e-2f0d-48fd-91d4-95684d653e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, return_sequences=True, **kwargs):\n",
    "        super(Attention, self).__init__()\n",
    "        self.return_sequences = return_sequences\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Attention, self).get_config().copy()\n",
    "        config.update({\n",
    "            'return_sequences': self.return_sequences,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.squeeze(K.tanh(K.dot(x, self.W) + self.b), axis=-1)\n",
    "        a = K.softmax(e)\n",
    "        a = K.expand_dims(a, axis=-1)\n",
    "        output = x * a\n",
    "\n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073cf848-0170-402a-baad-839408578245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 15:26:54.801594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 15:26:55.254911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a0:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Embed MODEL LOADED\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "def loadModel(name, PATH, X):\n",
    "    model = load_model(PATH, custom_objects={'Attention': Attention})\n",
    "    print(name + \" MODEL LOADED\\n\\n\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "PATH = './Politeness_Custom-Embedding-BiLSTM.h5'\n",
    "custom_model = loadModel('Custom Embed', PATH, custom_val_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15522b59-9966-4f5e-acfe-5e1e6b22c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 15:27:01.699859: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1108 [..............................] - ETA: 33s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 15:27:02.452939: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108/1108 [==============================] - 31s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "def adjustIndex(arr):\n",
    "    return [x+1 for x in arr]\n",
    "#%%\n",
    "\n",
    "y_pred_Custom = custom_model.predict(custom_val_embeds)\n",
    "\n",
    "y_pred_Custom_idx = adjustIndex(np.argmax(y_pred_Custom, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a370ec83-9f24-4be8-be3f-5749f22a9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# CONCATENATE RESULTS\n",
    "results = pd.DataFrame()\n",
    "results['review_id'] = df.review_id\n",
    "results['reviews'] = df.review\n",
    "results['politeness'] = y_pred_Custom_idx\n",
    "results.to_csv('iclr_2019_politeness.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce0403-e3ab-43a8-a10e-afa122fbc88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c0da3-7fa3-4d9b-9e64-fde8db60527e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
